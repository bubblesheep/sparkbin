---
title: "SparkBin"
output: html_document
---

## Optimal Binning For Spark Using Sparklyr

Spark provides a general machine learning library -- MLlib -- that is designed for simplicity, scalability, and easy integration with other tools. With the scalability, language compatibility, and speed of Spark, data scientists can solve and iterate through their data problems faster. 

In classic regression problems, binning is a common practice to reduce the effects of minor observation errors. It is especially helpful when non-linearity relationship is present and model complexity is undesired. Binning can be applied on both numerical or categorical variables, and metrics such as information value and weight of evidence can help guide the optimal binning procedures in classification problems. In standard R, there already exists functions for autobinning. In this package, we developed autobinning functions for binary classification in Spark to work seamlessly with MLlib library for big data modeling!



### Installing and preparing 

The *sparkbin* package will require packages *sparklyr* and *dplyr*.

```{r warning = FALSE, message = FALSE}
#load sparklyr & dplyr
if (!require(sparklyr)) install.packages("sparklyr")
library(dplyr)
library(sparkbin)

# Connecting to spark using spark_connect, on a local connection. 
sc <- spark_connect("local", config = spark_config())
```


### Development Steps

#### 1. Data and Spark Connection

We selected the lending club data (https://www.kaggle.com/wendykan/lending-club-loan-data) as a prepared data with target (0/1) and various candidate features that do not need to be pre-processed. 

```{r echo = FALSE, warning = FALSE}
# Create Spark connection and load data----------------------------------------
lending_tbl <- spark_read_csv(sc, "lending", "./sampledata/loan.csv")

# Only select a subset of features for this excersise
sdf <- lending_tbl %>%
  mutate(target = ifelse(
    loan_status %in% c("Current", "Issued", "Fully Paid"), 0, 1)) %>%
  select(id, annual_inc, delinq_2yrs, dti, emp_length,
         grade, home_ownership, installment,  purpose,
         term, target) %>%
  sdf_register("sdf")

tbl_cache(sc, "sdf")
```

A snapshot of *sdf*:
```{r echo = FALSE}
head(sdf)
```



#### 2. Initial Binning
We created **intervalbin** and **nominalbin** binning classes for numeric and character data types. Initial binning is performed to transform the variable into a number of fine classes by equal count. After applying initial binning, the data is small enough to proceed with optimal binning in local R environment. 

An example of applying initial binning to a numeric variable to generate 100 bins. The output is an object that contains:

- *cuts*: the cutting points from *-Inf* to *Inf*
- *good*: number of positive labels in each bin
- *bad*: number of negative labels in each bin
- *_Missing_*: number of *good* and *bad* labels for missing data

```{r echo = FALSE, warning = FALSE, cache = TRUE}
# get initial cuts for annual income
# bin_init_num(data, 'input variable', 'target variable', initial number of bins)
df <- bin_init_num(sdf, 'annual_inc', 'target', 10)
df
```


An example of applying initial binning to a character variable. The output is an object that contains:

- *xlevels* - including major levels (> minp) and two special levels "_Missing_" and "_Other_"(< minp)
- *ylevels* - mapped new levels, in the initial binning it should be same as xlevels
- *good* - number of goods in each xlevel
- *bad* - number of bads in each xlevel

```{r warning = FALSE, cache = TRUE}
# get initial cuts for homeownership
# bin_init_char(data, 'input variable', 'target variable', minp)
df <- bin_init_char(sdf, 'home_ownership', 'target', .01)
df
```


#### 3. Optimal Binning
The optimal binning uses a [recursive partitioning tree method](https://cran.r-project.org/web/packages/party/party.pdf) to optimize the number of bins of a given variable. The output of optimal binning is in the same class and structure as initial binning. *bin_tree* has two classes *intervalbin* and *nominalbin*, and *bin_tree()* automatically detects the class of the input and returns the same class and structure as initial binning.

An example of applying optimal binning to *home_ownership* after initial binning. The *plot()* method visualizes the optimized bins with new group names and weight of evidence (WOE) of each bin.  

```{r warning = FALSE, cache = TRUE}
df_opt <- bin_tree(df)
p <- plot(df_opt)
print(p)
```


#### 4. Binning Transformation 
The optimal binning object is transformed to a Spark data frame with the new group names mapped and ready for modeling using *MLlib*.


### Modeling Example

With the *sparkbin* package, feature engineering can be easily done in a few steps. Below is an example using the binned data to fit a logistic regression model in Spark.

```{r warning = FALSE, cache = TRUE, message = FALSE}

# specify numeric features and character features
features <- sapply(sdf_schema(sdf %>% select(-target)), function(x) x$type)
num_features <- names(features)[features %in% c("IntergerType", "DoubleType")]
char_features <- names(features)[features == "StringType"]

# Train/Test split-------------------------------------------------------------
partitions <- sdf_partition(sdf, training = 0.6, test = 0.4)
train <- partitions$train %>% sdf_register("train")
test <- partitions$test

tbl_cache(sc, "train")
