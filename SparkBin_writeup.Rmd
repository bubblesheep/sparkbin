---
title: "SparkBin"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Optimal Binning For Spark Using Sparklyr

Spark provides a general machine learning library -- MLlib -- that is designed for simplicity, scalability, and easy integration with other tools. With the scalability, language compatibility, and speed of Spark, data scientists can solve and iterate through their data problems faster. 

In classic regression problems, binning is a common practice to reduce the effects of minor observation errors. It is especially helpful when non-linearity relationship is present and model complexity is undesired. Binning can be applied on both numerical or categorical variables, and metrics such as information value and weight of evidence can help guide the optimal binning procedures in classification problems. In standard R, there already exists functions for autobinning. In this package, we developed autobinning functions for binary classification in Spark to work seamlessly with MLlib library for big data preprocessing!



### Installing and preparing sparklyr

The following lines of code will install sparklyr and the lastest version of spark. sparklyr works with a full integration of the dplyr package.

```{r eval = F}
#load sparklyr & dplyr
devtools::install_github("rstudio/sparklyr")
library(sparklyr)
library(dplyr)
library(sparkbin)

# install spark
spark_install(version = "1.6.2")
# Connecting to spark using spark_connect, on a local connection. 
sc <- spark_connect(master = "local")
```


### Development Steps

#### 1. Data and Spark Connection

We selected the lending club data (https://www.kaggle.com/wendykan/lending-club-loan-data) as a prepared data with target (0/1) and various candidate features that do not need to be pre-processed. 

```{r eval = F}
# Create Spark connection and load data----------------------------------------
sc <- spark_connect("local", config = spark_config())

lending_tbl <- spark_read_csv(sc, "lending", "sampledata/loan.csv")

# Only select a subset of features for this excersise
sdf <- lending_tbl %>%
  mutate(target = ifelse(
    loan_status %in% c("Current", "Issued", "Fully Paid"), 0, 1)) %>%
  select(id, annual_inc, delinq_2yrs, dti, emp_length,
         grade, home_ownership, installment,  purpose, sub_grade,
         term, target) %>%
  sdf_register("sdf")

tbl_cache(sc, "sdf")
```

A snapshot of *sdf*:


#### 2. Initial Binning
We created **intervalbin** and **nominalbin** binning classes for numeric and character data types. Initial binning is performed to transform the variable into a number of fine classes by equal count. After applying initial binning, the data is small enough to proceed with optimal binning in local R environment. 

An example of applying initial binning to a numeric variable to generate 100 bins. The output is an object that contains:

- *cuts*: the cutting points from *-Inf* to *Inf*
- *good*: number of positive labels in each bin
- *bad*: number of negative labels in each bin
- *_Missing_*: number of *good* and *bad* labels for missing data

```{r eval = FALSE}
# get initial cuts for annual income
df <- bin_init_num(sdf, 'annual_inc', 'target', 100)
```


An example of applying initial binning to a character variable. The output is an object that contains:

**FILL OUT!!!**

```{r eval = FALSE}
# get initial cuts for homeownership
df <- bin_init_char(sdf, 'home_ownership', 'target', .01)
plot(df)
```

```{r include=FALSE, echo=FALSE}
#print(sdf)
```


#### 3. Optimal Binning
The optimal binning uses tree based methods to optimize the number of bins of a given variable. The output of optimal binning should be in same class and same structure as initial binning.

An example of applying optimal binning to a numeric variable after initial binning. 

```{r eval = FALSE}
# get initial cuts for homeownership
df_opt <- bin_tree(df)
plot(df_opt)
```


#### 4. Binning Transformation 
The optimal binning object is transformed to a spark data frame using sparklyr for modeling using *MLlib*.

An example using the binned data to fit a logistic regression model:


